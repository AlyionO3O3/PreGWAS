#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Nov 30 00:15:10 2022

@author: alyion
"""
import pandas as pd
import numpy as np
import math
from tqdm import tqdm
import random
tqdm.pandas()

# This code is for TWB survey data cleansing in order to conduct further GWAS analysis
# 6 files are needed, column names may differ from time to time

class TWBcleaning():
    def __init__(self, filepath, gwaspath, survey_df, measure_df, mapping_df, kinship, pca, fam_df):
        self.filepath = filepath
        self.gwaspath = gwaspath
        print("\n>>Loading TWB survey data...")
        self.survey_df = pd.read_csv(self.filepath + survey_df, header=0)
        print("\n>>Loading TWB measure data...")
        self.measure_df = pd.read_csv(self.filepath + measure_df, header=0)
        print("\n>>Loading TWB mapping data...")
        self.mapping_df = pd.read_csv(self.filepath + mapping_df, header=0)
        print("\n>>Loading TWB kinship data...")
        self.kinship = pd.read_csv(self.gwaspath + kinship, sep="\t", header=0)
        print("\n>>Loading TWB PCA data...")
        self.pca = pd.read_csv(self.gwaspath + pca, sep="\t", header=0)
        print("\n>>Loading TWB GWAS fam file...")
        self.fam_df = pd.read_csv(self.gwaspath + fam_df, header=None, delimiter=" ")
        self.create_ID_Batch_dict()
        self.KINSHIP_to_Remove()
        YN = input("\n>>Do you need to merge TWB file?\n(Make sure your merged file locates in your path and file named as TWBmergeall.csv) (Y/N): ")
        if YN == "Y":
            self.merge3file()
        else:
            print("\n>>Loading TWB merge file...")
            self.TWB_df = pd.read_csv(self.filepath + "TWBmergeall.csv", header=0)
        self.PCA_10()
        self.BorF()
        YN = input("\n>>Do you need to create Pheno.csv?\n(Make sure your pheno file locates in your path and file named as Pheno.csv) (Y/N): ")
        if YN == "Y":
            self.create_Phenos()
        else:
            print("\n>>Loading pheno file...")
            self.pheno_df = pd.read_csv(self.filepath + "Pheno.csv", header=0)
        self.FAMindex()
        
    def eGFR(self, sex, scr, age):
        if math.isnan(scr):
            return np.NaN
        else:
            if sex == 2:
                return 186 * pow(scr,-1.154) * pow(age, -0.203) * 0.742
            elif sex == 1:
                return 186 * pow(scr,-1.154) * pow(age, -0.203)
            else:
                return np.NaN
    
    def OP(self, tscore):
        if math.isnan(tscore):
            return np.NaN
        else:
            if tscore <= -2.5:
                return 2 # case
            elif tscore >= -1:
                return 1 # control
            else:
                return np.NaN # osteopenia
            
    def OPe(self, tscore):
        if math.isnan(tscore):
            return np.NaN
        else:
            if tscore >= -1:
                return 1 # control
            elif tscore <= -2.5:
                return np.NaN 
            else:
                return 2 # osteopenia
    
    def OA(self, arthritis, arth_self, arth_kind):
        if math.isnan(arthritis):
            return np.NaN
        elif arthritis == 1 & math.isnan(arth_self):
            return 1 #control
        elif arthritis == 0:
            return 1 #control
        elif arth_self == 1 & ("退化" in str(arth_kind)):
            return 2 #case
        else:
            return 0 #other arthritis
        
        
    def UACR(self, UmiALB,Ucr):
        if math.isnan(UmiALB) or math.isnan(Ucr):
            return np.NaN
        else:
            return (UmiALB*100)/Ucr
    
    def CKD(self, egfr, uacr):
        if math.isnan(egfr) or math.isnan(uacr):
            return np.NaN
        elif egfr < 60 and uacr >= 30:
            return 2
        else:
            return 1
        
    def DN(self, diabete, CKD):
        if math.isnan(diabete) or math.isnan(CKD):
            return np.NaN
        elif diabete == 1 and CKD == 2:
            return 2
        else:
            return 1
        
    def TOCSV(self, df, path, name):
        chunks = np.array_split(df.index, 100)
        for chunck, subset in enumerate(tqdm(chunks)):
            if chunck == 0: # first row
                df.loc[subset].to_csv(path + name, mode='w', index=True)
            else:
                df.loc[subset].to_csv(path + name, header=None, mode='a', index=True)
                
    def TOTXT(self, df, path, name, h = True):
        chunks = np.array_split(df.index, 100)
        for chunck, subset in enumerate(tqdm(chunks)):
            if chunck == 0: # first row
                df.loc[subset].to_csv(path + name, mode='w', header=h, index=None, sep=' ')
            else:
                df.loc[subset].to_csv(path + name, header=None, mode='a', index=None, sep=' ')
    
    def create_ID_Batch_dict(self):
        self.mapping_df["iid"] = self.mapping_df["TWB1_ID"].combine_first(self.mapping_df["TWB2_ID"])
        self.mapping_df["batch"] = self.mapping_df["TWB1_Batch"].combine_first(self.mapping_df["TWB2_Batch"])
        ID_batch_df = self.mapping_df[["Release_No","iid","batch"]]
        ID_batch_df.set_index("Release_No", drop=True, inplace=True)
        ID_batch_df.dropna(subset = "iid", inplace = True)
        self.ID_batch_dict = ID_batch_df.to_dict(orient="index")
        print("\n>>create_ID_Batch_dict done!")
    
    def KINSHIP_to_Remove(self):            
        self.remove_df = pd.DataFrame(columns=["FID","IID"])
        remove_k = self.kinship[['FID', 'IID']]
        self.remove_df = self.remove_df.append(remove_k, ignore_index=True)
        self.remove_df = self.remove_df.drop_duplicates()
        print("\n>>Creating remove.txt...")
        self.TOTXT(self.remove_df, self.filepath, 'remove.txt')
        print("\n>>KINSHIP_to_Remove done!")
    
    def merge3file(self):
        print("\n>>Start merging survey and measure file...")
        self.TWB_df = pd.merge(self.survey_df, self.measure_df, on = ["Release_No","FOLLOW","PROJECT",'SURVEY_DATE','CRF_NAME_QN'], how = "outer")
        self.TWB_df["iid"] = self.TWB_df.Release_No.map(pd.DataFrame(self.ID_batch_dict).iloc[0])
        self.TWB_df["batch"] = self.TWB_df.Release_No.map(pd.DataFrame(self.ID_batch_dict).iloc[1])
        print("\n>>Creating TWBmergeall.csv...")
        self.TOCSV(self.TWB_df, self.filepath, 'TWBmergeall.csv')
        print("\n>>merge3file done!")
        
    def PCA_10(self):
        self.pca10 = self.pca[["FID","IID","PC1","PC2","PC3","PC4","PC5","PC6","PC7","PC8","PC9","PC10"]]
    
    def BorF(self):
        ans = input("\n>>Keeping only Baseline or Follow? (B/F/N): ")
        if ans == "N":
            print("\n>>Keeping both baseline and follow samples...")
        elif ans == "B":
            print("\n>>Dropping follow...")
            self.TWB_df = self.TWB_df[self.TWB_df.FOLLOW != "Follow 1"]
        else:
            print("\n>>Dropping baseline...")
            self.TWB_df = self.TWB_df[self.TWB_df.FOLLOW != "Baseline"]
    
    def create_Phenos(self):
        print("\n>>Creating phenotypes!")
        print("\n>>Calculating eGFR...")
        self.TWB_df["eGFR"] = self.TWB_df.progress_apply(lambda x: self.eGFR(x["SEX"],x["CREATININE"],x["AGE"]),axis=1)
        print("\n>>Finish calculating eGFR, now grouping OPe...")
        self.TWB_df["OPe"] = self.TWB_df.progress_apply(lambda x: self.OPe(x["T_SCORE"]),axis=1)
        print("\n>>Finish grouping OPe, now grouping OP...")
        self.TWB_df["OP"] = self.TWB_df.progress_apply(lambda x: self.OP(x["T_SCORE"]),axis=1)
        print("\n>>Finish grouping OP, now grouping OA...")
        self.TWB_df["OA"] = self.TWB_df.progress_apply(lambda x: self.OA(x["ARTHRITIS"],x["ARTHRITIS_SELF"],x["ARTHRITIS_SELF_KIND"]),axis=1)
        print("\n>>Finish grouping OA, now grouping eGFR setting cutoff at 60...")
        self.TWB_df["eGFR_stage60"] = self.TWB_df["eGFR"].progress_apply(lambda x: np.NaN if math.isnan(x) == True else (2 if x < 60 else 1))
        print("\n>>Finish grouping eGFR, now cleaning miALB and UCR...")
        self.TWB_df.MICROALB = self.TWB_df.MICROALB.progress_apply(lambda x: str(x).replace(',',''))
        self.TWB_df.MICROALB = self.TWB_df.MICROALB.progress_apply(lambda x: str(x).replace('<',''))
        self.TWB_df.MICROALB = self.TWB_df.MICROALB.progress_apply(lambda x: str(x).replace('>',''))
        self.TWB_df.MICROALB = self.TWB_df.MICROALB.astype(float)
        self.TWB_df.CREATININE_URINE = self.TWB_df.CREATININE_URINE.progress_apply(lambda x: str(x).replace(',',''))
        self.TWB_df.CREATININE_URINE = self.TWB_df.CREATININE_URINE.progress_apply(lambda x: str(x).replace('<',''))
        self.TWB_df.CREATININE_URINE = self.TWB_df.CREATININE_URINE.progress_apply(lambda x: str(x).replace('>',''))
        self.TWB_df.CREATININE_URINE = self.TWB_df.CREATININE_URINE.astype(float)
        print("\n>>Finish cleaning miALB and UCR, now calculating UACR...")
        self.TWB_df["UACR"] = self.TWB_df.progress_apply(lambda x: self.UACR(x["MICROALB"],x["CREATININE_URINE"]),axis = 1)
        print("\n>>Finish calculating UACR, now using KDIGO classifying CKD...")
        self.TWB_df["CKD_KDIGO"] = self.TWB_df.progress_apply(lambda x: self.CKD(x["eGFR_stage60"],x["UACR"]),axis = 1)
        print("\n>>Finish classifying CKD, now classifying DN...")
        self.TWB_df["DN"] = self.TWB_df.progress_apply(lambda x: self.DN(x["DIABETES_SELF"],x["CKD_KDIGO"]),axis = 1)
        print("\n>>All phenotypes done!")
        print("\n>>Dropping empty and duplicate IIDs...")
        self.TWB_df = self.TWB_df.sort_values('FOLLOW')
        self.TWB_df = self.TWB_df.dropna(subset='iid')
        self.TWB_df.drop_duplicates(subset="iid", keep="last", inplace = True)
        self.pheno_df = self.TWB_df[["iid", "batch","FOLLOW","SEX","BMI","AGE","T_SCORE","OPe","OP","OA","CREATININE","MICROALB","CREATININE_URINE","RENAL_FAILURE_SELF", "DIABETES_SELF","UACR", "eGFR_stage60", "CKD_KDIGO", "DN"]]
        self.TOCSV(self.pheno_df, self.filepath, 'Pheno.csv')
    
    def FAMindex(self):
        self.fam_df.columns = ["FID","IID","father","mother","sex","pheno"]
        self.index_df = self.fam_df[["FID","IID"]]
        
    def update_FAM(self):
        while True:
            phenos = str(list(self.pheno_df.columns)[3:]).replace("]", "").replace("[", "").replace("'", "")
            print("\n"+phenos)
            PHENO = input("\n>>Which pheno do you want to update for your fam file: ")
            if PHENO in self.pheno_df.columns:
                pheno_for_fam = self.pheno_df[["iid", PHENO]]
                pheno_for_fam.columns = ["IID","Pheno"]
                self.fam_df = self.fam_df[["FID","IID","father","mother","sex"]]
                self.fam_df = pd.merge(self.fam_df, pheno_for_fam, on = "IID", how = "left")
                self.fam_df["Pheno"] = self.fam_df["Pheno"].fillna(-9).astype('int')
                print("\n>>Updating phenotype.fam file...")
                self.TOTXT(self.fam_df, self.filepath, "combined.TWB1.TWB2.high.confidence.v3.fam",False)
                break
            print("\n>>Invalid phenotype!")
    
    def create_PHEs(self):
        PHENO = input('\n>>Which pheno do you want to create for your phenotype.txt file\n(no ned to include quotation marks, e.g., OA, OP): ')
        vals = [v.strip() for v in PHENO.split(',')]
        vals.insert(0,"iid")
        phenotxt = self.pheno_df[vals]
        phenotxt["FID"] = phenotxt.iid
        vals.insert(0,"FID")
        phenotxt = phenotxt[vals]
        phenotxt = phenotxt.rename({'iid':'IID'}, axis=1)
        self.TOTXT(phenotxt, self.filepath, "phenotype.txt")
    
    def create_COVs(self):
        print("\n>>Extracting covariates from pheno_df...")
        self.cov_df = self.pheno_df[["iid","batch","SEX","BMI","AGE"]]
        self.cov_df.columns = ["IID","batch","SEX","BMI","AGE"]
        self.cov_df = pd.merge(self.index_df, self.cov_df, on = ["IID"], how = "left")
        self.cov_df = pd.merge(self.cov_df, self.pca10, on = ["FID","IID"], how = "left")
        self.cov_df.dropna(inplace=True)
        print("\n>>Creating covariate.txt...")
        self.TOTXT(self.cov_df, self.filepath, "covariate.txt")

    def random_sampling(self):
        print("\n>>Start random process...")
        random.seed(10)
        keep_df = self.fam_df[~self.fam_df.IID.isin(self.remove_df.IID)]
        print(keep_df.Pheno.value_counts())
        n_case = input("\n>>According to total sample size above, how many cases do you need to sample: ")
        n_control = input("\n>>How many controls do you need to sample: ")
        print("\n>>Sampling target set...")
        targetcase = keep_df.IID[keep_df.Pheno==2].sample(n=int(n_case), random_state=1).tolist()
        targetcontrol = keep_df.IID[keep_df.Pheno==1].sample(n=int(n_control), random_state=1).tolist()
        targetID = []
        targetID.extend(targetcase)
        targetID.extend(targetcontrol)
        targetID_df = pd.DataFrame({"FID":targetID,"IID":targetID},columns=["FID","IID"])
        print("\n>>Creating targetID.txt...")
        self.TOTXT(targetID_df, self.filepath, "targetID.txt")
        print("\n>>Sampling base set...")
        baseID = keep_df.IID[~keep_df.IID.isin(targetID)].tolist()
        baseID_df = pd.DataFrame({"FID":baseID,"IID":baseID},columns=["FID","IID"])
        print("\n>>Creating baseID.txt...")
        self.TOTXT(baseID_df, self.filepath, "baseID.txt")
        
def main():
    TWB20221202 = TWBcleaning("/Volumes/Untitled/TWB20221129/","/Volumes/Untitled/TWBGWAS_130K/","release_list_survey.csv","release_list_measure.csv","lab_info.csv",'combined.TWB1.TWB2.high.confidence.v3.kinship.txt','combined.TWB1.TWB2.high.confidence.v3.PCA.txt',"combined.TWB1.TWB2.high.confidence.v3.fam")
    TWB20221202.update_FAM()
    YN = input("\n>>Do you want to create phenotype.txt for multiple phenos? (Y/N): ")
    if YN == "Y":        
        TWB20221202.create_PHEs()
    else:
        print("\n")
    YN = input(">>Do you want to create covariate file? (Y/N): ")
    if YN == "Y":
        TWB20221202.create_COVs()
    else:
        print("\n")
    YN = input(">>Do you need to sample file into target and base? (Y/N): ")
    if YN == "Y":
        TWB20221202.random_sampling()
    else:
        print("\n")
    print(">>All code done!")

    
if __name__ == "__main__": main()
